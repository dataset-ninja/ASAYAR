The creators of the **ASAYAR: A Dataset for Arabic-Latin Text Detection** gathered 1765 images along Moroccan highways, encompassing two complete journeys totaling around 2000 km. These trips consist of the first route from Oujda to Rabat and the second from Tangier to Casablanca. The images were captured using a Nikon D3300 camera with 24 megapixels and a Samsung Galaxy S7 smartphone camera with 13 megapixels. They encompass a variety of Moroccan highway signs, including those with Arabic/French text, regulatory indications, and warning traffic signs. The data annotation process took into account environmental factors.

The labelers of ASAYAR invested over 2000 hours of work, spanning nine months, to manually annotate the dataset. The annotated detection dataset is organized into one of three ***type*** groups: ASAYAR_SIGN for traffic sign objects, ASAYAR_TXT for text-based panels with word and line level annotations, and ASAYAR_SYM for panels featuring annotated directional symbols.

The authors employed the stratified sampling method to divide the sub-datasets into training (80%) and testing (20%) sets, ensuring balanced classes in each. For ASAYAR_SIGN, the training set comprises 1416 images, with 349 in the testing set. ASAYAR_TXT includes 1100 training samples and 275 testing samples, incorporating both word-level and line-level datasets. Lastly, ASAYAR_SYM has 444 images for training and 114 for testing.
